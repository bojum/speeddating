[
<<<<<<< HEAD
["results.html", "Chapter 5 Results 5.1 Question: Will backrgound and common interests influence the match? Which feature is the most influential? 5.2 Question: do people with excess self-esteem get more romantic interest?", " Chapter 5 Results 5.1 Question: Will backrgound and common interests influence the match? Which feature is the most influential? To answer this question, we have to look at background and common interests seperately. Background includes three features: race, from, and field. We can do so by comparing the chance of matching by conditioning on whether they are from the same race, same from (location), and same field. Data Cleaning: we would like to append 6 indicator columns that indicates whether this person and his/her partner share that feature in common (actually 5 because samerace is available in the original data). library(ggplot2) library(tidyverse) library(vcd) ## Loading required package: grid library(jsonlite) ## ## Attaching package: &#39;jsonlite&#39; ## The following object is masked from &#39;package:purrr&#39;: ## ## flatten load(&#39;data/speed_dating.RData&#39;) # get feature values of the partner for (i in 1:nrow(speed_dating)) { # for each row, get partner&#39;s id pid = speed_dating[i, &#39;pid&#39;] # add temporary columns that holds partner&#39;s location, field, sports, reading, movies speed_dating[i, &#39;plocation&#39;] = speed_dating[which(speed_dating$iid == pid)[1], &#39;from&#39;] speed_dating[i, &#39;pfield&#39;] = speed_dating[which(speed_dating$iid == pid)[1], &#39;field&#39;] } # append indicator columns for location, field, and income speed_dating[&#39;samelocation&#39;] &lt;- if_else(speed_dating$from == speed_dating$plocation, &#39;Yes&#39;, &#39;No&#39;) speed_dating[&#39;samefield&#39;] &lt;- if_else(speed_dating$field == speed_dating$pfield, &#39;Yes&#39;, &#39;No&#39;) # get the feature values of all the hobbies of the partner f &lt;- function(x){ tmp &lt;- data.frame(&quot;holder&quot; = 1:dim(speed_dating)[1]) result &lt;- data.frame(&quot;holder&quot; = 1:dim(speed_dating)[1]) for (i in 1:nrow(speed_dating)){ pid = speed_dating[i, &#39;pid&#39;] tmp[i,1] &lt;- speed_dating[which(speed_dating$iid == pid)[1], x] } for (i in 1:nrow(speed_dating)) { result[i,1] &lt;- if_else((tmp[i,1] &gt;=7 &amp; speed_dating[i,x]&gt;=7), &#39;Yes&#39;, &#39;No&#39;) } return(result) } names = colnames(speed_dating %&gt;% select(sports:yoga)) common_features &lt;- as.data.frame(do.call(cbind,lapply(names, f))) colnames(common_features)&lt;- paste0(&#39;same&#39;,colnames(speed_dating %&gt;% select(sports:yoga))) speed_dating &lt;- cbind(speed_dating, common_features) speed_dating &lt;- speed_dating[, !duplicated(colnames(speed_dating))] # drop unecessary columns and missing data drops = c(&#39;plocation&#39;, &#39;pfield&#39;) keeps = append(colnames(speed_dating %&gt;% select(sports:yoga)), c(&#39;samelocation&#39;, &#39;samefield&#39;)) speed_dating_q1 &lt;- speed_dating[complete.cases(speed_dating[,keeps]), ] ## end here #save(speed_dating_q1, file = &quot;data/speed_dating_q1.Rdata&quot;) load(file = &quot;data/speed_dating_q1.Rdata&quot;) speed_dating &lt;- speed_dating_q1 names = colnames(speed_dating %&gt;% select(sports:yoga)) # for mosaic plot # create a clean dataframe for each common feature sameracedata = speed_dating %&gt;% group_by(samerace, match) %&gt;% summarise(Freq = n()) %&gt;% ungroup() %&gt;% mutate(samerace = if_else(samerace == 1, &quot;Yes&quot;, &quot;No&quot;)) %&gt;% mutate(match = if_else(match == 1, &quot;Yes&quot;, &quot;No&quot;)) samelocationdata = speed_dating %&gt;% group_by(samelocation, match) %&gt;% summarize(Freq = n()) %&gt;% ungroup() %&gt;% mutate(match = if_else(match == 1, &quot;Yes&quot;, &quot;No&quot;)) samefielddata = speed_dating %&gt;% group_by(samefield, match) %&gt;% summarize(Freq = n()) %&gt;% ungroup() %&gt;% mutate(match = if_else(match == 1, &quot;Yes&quot;, &quot;No&quot;)) samesportsdata = speed_dating %&gt;% group_by(samesports, match) %&gt;% summarize(Freq = n()) %&gt;% ungroup() %&gt;% mutate(match = if_else(match == 1, &quot;Yes&quot;, &quot;No&quot;)) samereadingdata = speed_dating %&gt;% group_by(samereading, match) %&gt;% summarize(Freq = n()) %&gt;% ungroup() %&gt;% mutate(match = if_else(match == 1, &quot;Yes&quot;, &quot;No&quot;)) samemoviesdata = speed_dating %&gt;% group_by(samemovies, match) %&gt;% summarize(Freq = n()) %&gt;% ungroup() %&gt;% mutate(match = if_else(match == 1, &quot;Yes&quot;, &quot;No&quot;)) cat( paste( &#39;&lt;script&gt; var sameracedata = &#39;,toJSON(sameracedata),&#39;; var samelocationdata = &#39;,toJSON(samelocationdata),&#39;; var samefielddata = &#39;,toJSON(samefielddata),&#39;; var samesportsdata = &#39;,toJSON(samesportsdata),&#39;; var samereadingdata = &#39;,toJSON(samereadingdata),&#39;; var samemoviesdata = &#39;,toJSON(samemoviesdata),&#39;; &lt;/script&gt;&#39; , sep=&quot;&quot;) ) ## &lt;script&gt; ## var sameracedata = [{&quot;samerace&quot;:&quot;No&quot;,&quot;match&quot;:&quot;No&quot;,&quot;Freq&quot;:3398},{&quot;samerace&quot;:&quot;No&quot;,&quot;match&quot;:&quot;Yes&quot;,&quot;Freq&quot;:620},{&quot;samerace&quot;:&quot;Yes&quot;,&quot;match&quot;:&quot;No&quot;,&quot;Freq&quot;:2164},{&quot;samerace&quot;:&quot;Yes&quot;,&quot;match&quot;:&quot;Yes&quot;,&quot;Freq&quot;:476}]; ## var samelocationdata = [{&quot;samelocation&quot;:&quot;No&quot;,&quot;match&quot;:&quot;No&quot;,&quot;Freq&quot;:5516},{&quot;samelocation&quot;:&quot;No&quot;,&quot;match&quot;:&quot;Yes&quot;,&quot;Freq&quot;:1082},{&quot;samelocation&quot;:&quot;Yes&quot;,&quot;match&quot;:&quot;No&quot;,&quot;Freq&quot;:46},{&quot;samelocation&quot;:&quot;Yes&quot;,&quot;match&quot;:&quot;Yes&quot;,&quot;Freq&quot;:14}]; ## var samefielddata = [{&quot;samefield&quot;:&quot;No&quot;,&quot;match&quot;:&quot;No&quot;,&quot;Freq&quot;:5460},{&quot;samefield&quot;:&quot;No&quot;,&quot;match&quot;:&quot;Yes&quot;,&quot;Freq&quot;:1054},{&quot;samefield&quot;:&quot;Yes&quot;,&quot;match&quot;:&quot;No&quot;,&quot;Freq&quot;:102},{&quot;samefield&quot;:&quot;Yes&quot;,&quot;match&quot;:&quot;Yes&quot;,&quot;Freq&quot;:42}]; ## var samesportsdata = [{&quot;samesports&quot;:&quot;No&quot;,&quot;match&quot;:&quot;No&quot;,&quot;Freq&quot;:4012},{&quot;samesports&quot;:&quot;No&quot;,&quot;match&quot;:&quot;Yes&quot;,&quot;Freq&quot;:746},{&quot;samesports&quot;:&quot;Yes&quot;,&quot;match&quot;:&quot;No&quot;,&quot;Freq&quot;:1550},{&quot;samesports&quot;:&quot;Yes&quot;,&quot;match&quot;:&quot;Yes&quot;,&quot;Freq&quot;:350}]; ## var samereadingdata = [{&quot;samereading&quot;:&quot;No&quot;,&quot;match&quot;:&quot;No&quot;,&quot;Freq&quot;:2408},{&quot;samereading&quot;:&quot;No&quot;,&quot;match&quot;:&quot;Yes&quot;,&quot;Freq&quot;:424},{&quot;samereading&quot;:&quot;Yes&quot;,&quot;match&quot;:&quot;No&quot;,&quot;Freq&quot;:3154},{&quot;samereading&quot;:&quot;Yes&quot;,&quot;match&quot;:&quot;Yes&quot;,&quot;Freq&quot;:672}]; ## var samemoviesdata = [{&quot;samemovies&quot;:&quot;No&quot;,&quot;match&quot;:&quot;No&quot;,&quot;Freq&quot;:1570},{&quot;samemovies&quot;:&quot;No&quot;,&quot;match&quot;:&quot;Yes&quot;,&quot;Freq&quot;:344},{&quot;samemovies&quot;:&quot;Yes&quot;,&quot;match&quot;:&quot;No&quot;,&quot;Freq&quot;:3992},{&quot;samemovies&quot;:&quot;Yes&quot;,&quot;match&quot;:&quot;Yes&quot;,&quot;Freq&quot;:752}]; ## &lt;/script&gt; We then look at all the available features that could be of common interest in the dataset, and see if any of those features heavily impacts the chances of getting matched. calc_diff &lt;- function(x){ tmp &lt;- speed_dating %&gt;% group_by_(x, &#39;match&#39;) %&gt;% summarize(Freq = n()) %&gt;% ungroup() %&gt;% mutate(match = if_else(match == 1, &quot;Yes&quot;, &quot;No&quot;)) no_rate &lt;- tmp[2,3]/(tmp[2,3]+tmp[1,3]) yes_rate &lt;- tmp[4,3]/(tmp[3,3]+tmp[4,3]) return(yes_rate - no_rate) } cd_df &lt;- do.call(rbind,lapply(paste0(&#39;same&#39;,colnames(speed_dating %&gt;% select(sports:yoga))),calc_diff))*100 ## Warning: group_by_() is deprecated. ## Please use group_by() instead ## ## The &#39;programming&#39; vignette or the tidyeval book can help you ## to program with group_by() : https://tidyeval.tidyverse.org ## This warning is displayed once per session. cd_df &lt;- cbind(cd_df, names) ggplot(cd_df,aes(x=Freq,y=fct_reorder(names,Freq)))+geom_point(color=&quot;blue&quot;)+ylab(&quot;&quot;)+xlab(&quot;Percent (%)&quot;)+ggtitle(&quot;Differences in Chance of Matching&quot;) 5.2 Question: do people with excess self-esteem get more romantic interest? Self-enhancement is one kind of motivation that makes people feel good and boost their confidence (https://en.wikipedia.org/wiki/Self-enhancement). Epley and Whitchurch’s work is one evidence supporting the idea that people tend to see themselves better that the reality (https://journals.sagepub.com/doi/abs/10.1177/0146167208318601?journalCode=pspc). The phenomenon is also known as “illusory superiority”, where the majority of people evaluates themself as better than the average. It is widely believed that confident people preform better in various tasks including in relationships (see Link). This section of the analysis focuses on this idea. Specifically, we want to know if confident people get more interests during the Speed Dating session. Given the dataset, we define confidence, or excess self-esteem, as how much higher a subject evaluates itself than other people rate the subject (peer score). That is, the varaible excess self-esteem is calculated by subtracting an averaged evaluation score given by others from the score given to self. A large positive difference indicates highly excess self-esteem. A large negative difference suggests very low self-esteem. The variable is called self-esteem in the analysis and peer score is an average score a subject received from other people. http://images.lipy.com/women-vs-men One distinct characteristics of participants is gender. However, the previous question found no difference between genders. Moreover, this characteristics does not distinquish subjects in terms of their excess self-esteem. Below are distribution of score difference for each gender in each attribute. Their distribution are similar, peaking at around 1 with almost identical spread. attr_list &lt;- c(&quot;amb&quot;=&quot;Ambitious&quot;, &quot;attr&quot;=&quot;Attractive&quot;, &quot;fun&quot;=&quot;Fun&quot;, &quot;intel&quot;=&quot;Intelligent&quot;, &quot;sinc&quot;=&quot;Sincere&quot;) ggplot(eval_df %&gt;% mutate(gender = ifelse(gender == 0, &quot;Female&quot;, &quot;Male&quot;), gender = as.factor(gender), attr = attr_list[attr]), aes(x=diff_before, fill = gender)) + geom_density(alpha = 0.5) + ggtitle(&quot;Histogram of Evaluation Ratio&quot;) + xlab(&quot;Ratio&quot;) + facet_grid(~attr) When self-esteem is plotted against the proportion of people who want to meet with a subject again, referred to as interest proportion, the only small difference between gender is that female participants tend to get higher interest proportion than male participants. This is shown by more red dots locating at the top and more blue dots at the bottom of the graph. However, dots at the top and the bottom constitute only a small number of participants. Therefore, this analysis treat both genders collectively. ## color by gender ggplot(diff_df, aes(x=diff_before, y = proportion, color = gender)) + geom_point(alpha = 0.5) + facet_grid(~attr) + xlab(&quot;Self Esteem&quot;) + ylab(&quot;Interest Proportion&quot;) The plots above also suggest that people with excess self-esteem generally have low interest proportion. The correlation is stronger in fun and attractive, with the most negative correlation in attractive. That is, a participant with lower self-esteem in his/her own attractive and fun tend to get more romatic interest from the others. cor_list &lt;- lapply(eval_df$attr %&gt;% unique(), function(a){ attr_eval_df &lt;- eval_df%&gt;% ungroup() %&gt;% filter(attr == a) %&gt;% select(diff_before, proportion) c &lt;- cor(attr_eval_df$diff_before, attr_eval_df$proportion) return(data.frame(&quot;Attribute&quot;=a, &quot;Correlation&quot; = c)) }) attr_list &lt;- c(&quot;attr&quot;=&quot;Attractive&quot;, &quot;sinc&quot;=&quot;Sincere&quot;, &quot;amb&quot;=&quot;Ambitious&quot;, &quot;fun&quot;=&quot;Fun&quot;, &quot;intel&quot;=&quot;Intelligent&quot;) cor_df &lt;- do.call(rbind, cor_list) %&gt;% mutate(Attribute = attr_list[Attribute]) cor_df %&gt;% kable() %&gt;% kable_styling() Attribute Correlation Attractive -0.1857069 Sincere -0.4475117 Ambitious -0.2780918 Fun -0.3056818 Intelligent -0.1804723 The fact that attractive has the strongest correlation with interest proportion should not be surprising since it is the attribute that people look for the most in their partner (discussed in previous question). The next part narrows its focus down to attractive attribute only. Below is a plot of peer score against interest proportion. Data points are colored by self esteem. Darker color indicates a person with lower self-esteem. ggplot(diff_df %&gt;% filter(attr == &quot;attr&quot;) %&gt;% rename(self_esteem = diff_before), aes(x=peer_score , y = proportion, color = self_esteem)) + geom_point() + xlab(&quot;Peer Score&quot;) + ylab(&quot;Interest Proportion&quot;) The plot shows a linear relationship between peer evaluation score and interest proportion. A person who, othter people think, is attractive gain more romantic interest proportion, especially when average score is below 5. The linear relationship becomes weaker for those with score larger than 6. We also found that people who are less confident in their attractiveness tend to get more interests. This is shown by darker dots at the top right of the plot. Poeple with low self esteem gain more proportion of interest. Before jumping into a conclusion that being attractive is what matters, we inspect other characteristics of subjects. We are curious whether there are some confounding varaibles (other than what has been explored in the previous questions) that get a subject more romantic interest. All the graphs below are relationships between peer score on attractive and interest proportion. Dots are colored by other characterisitcs that we want to inspect. 5.2.0.1 Race race_list &lt;- c(&quot;Black/African American&quot;, &quot;European/Caucasian-American&quot;, &quot;Latino/Hispanic American&quot;, &quot;Asian/Pacific Islander/Asian-American&quot;, &quot;Native American&quot;, &quot;Other&quot;) pl1 &lt;- ggplot(diff_df %&gt;% filter(attr == &quot;attr&quot;) %&gt;% select(iid, race) %&gt;% group_by(race) %&gt;% summarize(cnt = n()) %&gt;% mutate(race = race_list[race]), aes(x = fct_reorder(race, cnt), y = cnt, fill = race)) + geom_col() + coord_flip() + xlab(&quot;&quot;) + ylab(&quot;count&quot;) + theme(legend.position = &quot;none&quot;) pl2 &lt;- ggplot(diff_df %&gt;% filter(attr == &quot;attr&quot;) %&gt;% mutate(race = race_list[race]), aes(x=peer_score, y = proportion, color = race)) + geom_point(alpha = 1) + xlab(&quot;Peer Score for Attractive&quot;) + ylab(&quot;Interest Proportion&quot;) ggplotly(pl1, tooltip = c(&quot;cnt&quot;)) ggplotly(pl2, tooltip = c(&quot;race&quot;)) #subplot(ggplotly(pl1, tooltip = c(&quot;cnt&quot;)), ggplotly(pl2, tooltip = c(&quot;race&quot;)),nrows=1) We find no pattern among proportion, peer_score, and race. 5.2.0.2 Field of Study field_list &lt;- c(&quot;Law&quot;, &quot;Math&quot;, &quot;Social Science&quot;, &quot;Psychologist&quot;, &quot;Medical Science&quot;, &quot;Pharmaceuticals and Bio Tech&quot;, &quot;Engineering&quot;, &quot;English/Creative Writing/ Journalism&quot;, &quot;History/Religion/Philosophy&quot;, &quot;Business/Econ/Finance&quot;, &quot;Education, Academia&quot;, &quot;Biological Sciences/Chemistry/Physics&quot;, &quot;Social Work&quot;, &quot;Undergrad/undecided&quot;, &quot;Political Science/International Affairs&quot;, &quot;Film&quot;, &quot;Fine Arts/Arts Administration&quot;, &quot;Languages&quot;, &quot;Architecture&quot;, &quot;Other&quot;) pl1 &lt;- ggplot(diff_df %&gt;% filter(attr == &quot;attr&quot;, !is.na(field_cd)) %&gt;% select(iid, field_cd) %&gt;% group_by(field_cd) %&gt;% summarize(cnt = n()) %&gt;% mutate(field_cd = field_list[field_cd]), aes(x = fct_reorder(field_cd, cnt), y = cnt, fill = field_cd)) + geom_col() + coord_flip() + xlab(&quot;&quot;) + ylab(&quot;count&quot;) + theme(legend.position = &quot;none&quot;) ## field X pl2 &lt;- ggplot(diff_df %&gt;% filter(attr == &quot;attr&quot;, !is.na(field_cd)) %&gt;% mutate(field_cd = field_list[field_cd]), aes(x=peer_score, y = proportion, color = field_cd)) + geom_point(alpha = 1) + xlab(&quot;Attractive Peer Score&quot;) + ylab(&quot;Interest Proportion&quot;) ggplotly(pl1, tooltip = c(&quot;cnt&quot;)) ggplotly(pl2, tooltip = c(&quot;field_cd&quot;)) #subplot(ggplotly(pl1, tooltip = c(&quot;cnt&quot;)), ggplotly(pl2, tooltip = c(&quot;field_cd&quot;)), nrows=1) fc &lt;- read.csv(&quot;data/field_cat.csv&quot;) %&gt;% mutate(cd = row_number()) cat_list &lt;- fc$cat %&gt;% as.character() names(cat_list) &lt;- fc$cd diff_df &lt;- diff_df %&gt;% mutate(field_cate_cd = cat_list[field_cd]) In addition to considering individual majors, we create major categories to see any general pattern that involves in school majors. pl1 &lt;- ggplot(diff_df %&gt;% filter(attr == &quot;attr&quot;, !is.na(field_cate_cd)) %&gt;% select(iid, field_cate_cd)%&gt;% group_by(field_cate_cd) %&gt;% summarize(cnt = n()), aes(x = fct_reorder(field_cate_cd, cnt), y = cnt, fill = field_cate_cd)) + geom_col() + coord_flip() + xlab(&quot;&quot;) + ylab(&quot;count&quot;) + theme(legend.position = &quot;none&quot;) pl2 &lt;- ggplot(diff_df %&gt;% filter(attr == &quot;attr&quot;, !is.na(field_cate_cd)), aes(x=peer_score, y = proportion, color = field_cate_cd)) + geom_point(alpha = 1) + theme(legend.position = &quot;none&quot;) + xlab(&quot;Attractive Peer Score&quot;) + ylab(&quot;Interest Proportion&quot;) ggplotly(pl1, tooltip = c(&quot;cnt&quot;)) ggplotly(pl2, tooltip = c(&quot;field_cate_cd&quot;)) #subplot(ggplotly(pl1, tooltip = c(&quot;cnt&quot;)), ggplotly(pl2, tooltip = c(&quot;field_cate_cd&quot;)), nrows=1) There is also no pattern among proportion, peer_score, and study field. As far as we know, attractiveness is the only characteristic that have the strongest correlation with interest propotion. In conclusion, we found that people with low self esteem in their attractiveness gain more romantic interest after the event. "]
=======
["index.html", "How to Get More Matches in Speed Dating Chapter 1 Introduction 1.1 Introduction 1.2 Background 1.3 Our Goal 1.4 Project Overview", " How to Get More Matches in Speed Dating Yingyu Cao (yc3713), Bo Jumrustanasan (pj2356), Zhi Qi (zq2175) 2019-12-12 Chapter 1 Introduction 1.1 Introduction What is love at first sight? Imagine meeting a girl or a guy that you really like, and you want to make a better impression. How should you act out? How do you know if you are a good match for him/her? This project will help you understand what are the important factors that will help you make a better impression. 1.2 Background We use speed experiment dating data collected by Columbia Business schooll as a foundation to the analyses in this project. Being popular since 1970s, speed dating is a formalized matchmaking process which enables singles to meet large numbers of new potential partners in a very short period of time (4 minutes in our data), which is the equivalent to having many “first sights” and being able to choose the potential partners that you like. If both participants like each other, then it is a “match” and they can exchange contact informations and such. For research purposes, participants in our data were asked to fill out several forms before and during the speed dating process. Our findings are based on such data. 1.3 Our Goal In this project, we explore what factors that influence the chances of getting a “match.” For example, will having a same hobby with your partner increase your chances? Or should you behave as confident you can to leave a better impression? If not, what things or factors are your partner looking for? We derive our focus on the factors that you can control. 1.4 Project Overview In section 2, we give an overview of our data, where it was from and what issues it may have. Then in section 3 &amp; 4, we describe our data cleaning/transformation process and patterns for missing values. In section 5, we provide our analyses and interesting findings, and the answers to those questions above will be in this section as well. In section 6, we include a interative section, where you can interact with the graphs and explore interesting findings on your own. We include our conclusions to this project in section 7. "],
["data-sources.html", "Chapter 2 Data sources 2.1 Experimental Design 2.2 Data Description", " Chapter 2 Data sources The dataset for our project is speed dating dataset provided by Anna Montoya. It is publicly available on Data.com as an excel file. The data contains information about match and questionnaire from a speed dating experiment in 2002-2004 that was run by professors Ray Fisman and Sheena Iyengar from Columbia Business School. The primamry purpose of the collection was for their paper Gender Differences in Mate Selection: Evidence From a Speed Dating Experiment. 2.1 Experimental Design The experiment is design based on Speed Dating which is an event where participants have a four-minute conversation and decide if they want to meet each other again. They will get the other’s contact information only if both parties “accept”. Subjects in the experiments were students in graduate and professional school at Columbia University during the time of the experiment. They learned about the event through mass e-mail and fliers on distributed on campus. They had to sign up for the event by providing the experimentors with their names and email addresses and completing a pre-event survey ononline website. There were 20 sessions of the experiment, all of which had the same setting. All participants were randomly assigned to one of the sessions. On the session day, participants who are unawared of the total number of participants on that day had to fill in a scorecard that contains Spaces to write the ID number of each person they met Yes/No whether a subject wants to meet the person again Six attributes on which a subject was to rate the person they met. The attributes are: Attractive Sincere Intelligent Fun Ambitious Shared Interests There were roughly the same number of female and male participants in each sessions. Subjects only had conversation with those of different genders. Female subjects would meet all male subjects in the session. The scorecard was to be filled after each four-minute conversation. The day after the Speed Dating event, particiapants were asked to complete the follow-up online questionaire in order to obtain their matches. For more detail on the experiment procedure, please check out the study. 2.2 Data Description The raw dataset from the source has 195 variables and 8378 rows. The number of rows do not represent the total number of participants in the experiment. The data provider had transformed the dataset by gathering to match some variables between a subject and each of its partner. We have further cleaned the dataset so that it includes only important variables (see more detail in data cleaning section). Variables in the analysis is summarized in the metadata below. data_dict &lt;- read.csv(file = &quot;data/metadata_var.csv&quot;) %&gt;% select(Variable, Description) data_dict %&gt;% kable %&gt;% kable_styling() %&gt;% kableExtra::scroll_box(width = &quot;100%&quot;, height = &quot;600px&quot;) Variable Description iid Unique subject number, wave Session number gender female/male race Race of a subject Black/African American=1 European/Caucasian-American=2 Latino/Hispanic American=3 Asian/Pacific Islander/Asian-American=4 Native American=5 Other=6 from Where are you from originally (before coming to Columbia)? field Field of study field_cd Field code 1= Law 2= Math 3= Social Science, Psychologist 4= Medical Science, Pharmaceuticals, and Bio Tech 5= Engineering 6= English/Creative Writing/ Journalism 7= History/Religion/Philosophy 8= Business/Econ/Finance 9= Education, Academia 10= Biological Sciences/Chemistry/Physics 11= Social Work 12= Undergrad/undecided 13=Political Science/International Affairs 14=Film 15=Fine Arts/Arts Administration 16=Languages 17=Architecture 18=Other [acticity] How interested are you in [activity] on a scale of 1-10? [activity] are sports, tvsports, exercise, dining, museums, art, hiking, gaming, clubbing, reading, tv, theater, movies, concerts, music, shopping, and yoga pid Partner’s iid number match Whether iid and pid are matched. 1=yes, 0=no dec_o Decision of partner the night of event samerace Whether iid and pid have the same race race_o Race of partner attr How attractive is a person you met, on a scale of 1-10? sinc How sincere is a person you met, on a scale of 1-10? intel How intelligent is a person you met, on a scale of 1-10? fun How fun is a person you met, on a scale of 1-10? amb How ambitious is a person you met, on a scale of 1-10? shar How much do you and a person you met share the same interest, on a scale of 1-10? like Overall, how much do you like this person? (1=don’t like at all, 10=like a lot) prob How probable do you think it is that this person will say ‘yes’ for you? (1=not probable, 10=extremely probable) goal The primary goal a subject participated in the event. 1 = Seemed like a fun night out 2 = To meet new people 3 = To get a date 4 = Looking for a serious relationship 5 = To say I did it 6 = Other Participants were also asked to rate five (and six in some cases) attributes for themselves and for people they met (i) before the event (if applicable), (ii) a day after the event, and (iii) 2 weeks after the event. The variable names are in the form of [attribute][#]_[#]. read.csv(file = &quot;data/metadata_attr.csv&quot;) %&gt;% kable %&gt;% kable_styling() %&gt;% kableExtra::scroll_box(width = &quot;100%&quot;, height = &quot;600px&quot;) Code Description [attr] attr = attractive sinc = sincere fun = fun intel = intelligent amb = ambitious shar = share the same interest [#1] 1 = Rate yourself 3 = Rate a person you meet [#2] 1 = questions asked before the event (if applicable) 2 = questions asked one day after the event 3 = questions asked two weeks after the event For more information about the raw data and questionaire, see the metadata from the dataset provider. "],
["data-transformation.html", "Chapter 3 Data transformation", " Chapter 3 Data transformation The raw dataset contains 195 variables with 8378 rows. Only a subset of 195 variables are included in our analysis (more detail for this step in data transformation section). Below is a script file that we use to clean the dataset. speed_dating &lt;- raw_dat %&gt;% select(iid,wave,gender,age,race,from,field,field_cd,undergra,mn_sat,tuition,income, imprace,expnum, sports:yoga, attr1_1:shar1_1, # exp weight to others-1 attr1_s:shar1_s, # exp weight to others-2 attr3_1:amb3_1, # self-evaluate-1 (self)-1 attr3_s:amb3_s, # self-evaluate-1 (self)-2 attr5_1:amb5_1, # self-evaluate-2 (others)-1 wave,pid,met_o,match,dec_o,int_corr,samerace,age_o,race_o, pf_o_att:pf_o_sha, # score to others attr_o:shar_o,like_o,prob_o, # score received attr1_2:shar1_2, # exp weight to others-3 attr3_2:amb3_2, # self-evaluate-1 (self)-3 attr5_2:amb5_2, # self-evaluate-2 (others)-2 you_call,them_cal, attr1_3:shar1_3, # exp weight to others-4 attr3_3:amb3_3, # self-evaluate-1 (self)-4 attr5_3:amb5_3, # self-evaluate-2 (others)-3 attr:shar,like,prob ) # add indicator columns # operate row by row for (i in 1:nrow(speed_dating)) { # for each row, get partner&#39;s id pid = speed_dating[i, &#39;pid&#39;] # add temporary columns that holds partner&#39;s location, field, sports, reading, movies speed_dating[i, &#39;plocation&#39;] = speed_dating[which(speed_dating$iid == pid)[1], &#39;from&#39;] speed_dating[i, &#39;pfield&#39;] = speed_dating[which(speed_dating$iid == pid)[1], &#39;field&#39;] speed_dating[i, &#39;psports&#39;] = speed_dating[which(speed_dating$iid == pid)[1], &#39;sports&#39;] speed_dating[i, &#39;preading&#39;] = speed_dating[which(speed_dating$iid == pid)[1], &#39;reading&#39;] speed_dating[i, &#39;pmovies&#39;] = speed_dating[which(speed_dating$iid == pid)[1], &#39;movies&#39;] } # append indicator columns that indicates whether this person and his/her partner share this feature speed_dating[&#39;samelocation&#39;] &lt;- if_else(speed_dating$from == speed_dating$plocation, &#39;Yes&#39;, &#39;No&#39;) speed_dating[&#39;samefield&#39;] &lt;- if_else(speed_dating$field == speed_dating$pfield, &#39;Yes&#39;, &#39;No&#39;) speed_dating[&#39;samesports&#39;] &lt;- if_else(speed_dating$psports &gt;=7 &amp; speed_dating$sports&gt;=7, &#39;Yes&#39;, &#39;No&#39;) speed_dating[&#39;samereading&#39;] &lt;- if_else(speed_dating$preading &gt;=7 &amp; speed_dating$reading&gt;=7, &#39;Yes&#39;, &#39;No&#39;) speed_dating[&#39;samemovies&#39;] &lt;- if_else(speed_dating$pmovies &gt;=7 &amp; speed_dating$movies&gt;=7, &#39;Yes&#39;, &#39;No&#39;) # drop unecessary columns and missing data drops = c(&#39;plocation&#39;, &#39;pfield&#39;, &#39;psports&#39;, &#39;preading&#39;, &#39;pmovies&#39;) keeps = c(&#39;samerace&#39;, &#39;samelocation&#39;, &#39;samefield&#39;, &#39;samesports&#39;, &#39;samesports&#39;, &#39;samemovies&#39;) speed_dating &lt;- speed_dating[ , !(names(speed_dating) %in% drops)] speed_dating &lt;- speed_dating[complete.cases(speed_dating[,keeps]), ] "],
["missing-values.html", "Chapter 4 Missing values", " Chapter 4 Missing values "],
["results.html", "Chapter 5 Results 5.1 Question: Will backrgound and common interests influence the match? Which feature is the most influential?", " Chapter 5 Results 5.1 Question: Will backrgound and common interests influence the match? Which feature is the most influential? To answer this question, we have to look at background and common interests seperately. Background includes three features: race, from, and field. We can do so by comparing the chance of matching by conditioning on whether they are from the same race, same from (location), and same field. Data Cleaning: we would like to append 6 indicator columns that indicates whether this person and his/her partner share that feature in common (actually 5 because samerace is available in the original data). library(ggplot2) library(tidyverse) library(vcd) library(jsonlite) load(&#39;data/speed_dating.RData&#39;) # get feature values of the partner for (i in 1:nrow(speed_dating)) { # for each row, get partner&#39;s id pid = speed_dating[i, &#39;pid&#39;] # add temporary columns that holds partner&#39;s location, field, sports, reading, movies speed_dating[i, &#39;plocation&#39;] = speed_dating[which(speed_dating$iid == pid)[1], &#39;from&#39;] speed_dating[i, &#39;pfield&#39;] = speed_dating[which(speed_dating$iid == pid)[1], &#39;field&#39;] } # append indicator columns for location, field, and income speed_dating[&#39;samelocation&#39;] &lt;- if_else(speed_dating$from == speed_dating$plocation, &#39;Yes&#39;, &#39;No&#39;) speed_dating[&#39;samefield&#39;] &lt;- if_else(speed_dating$field == speed_dating$pfield, &#39;Yes&#39;, &#39;No&#39;) # get the feature values of all the hobbies of the partner f &lt;- function(x){ tmp &lt;- data.frame(&quot;holder&quot; = 1:dim(speed_dating)[1]) result &lt;- data.frame(&quot;holder&quot; = 1:dim(speed_dating)[1]) for (i in 1:nrow(speed_dating)){ pid = speed_dating[i, &#39;pid&#39;] tmp[i,1] &lt;- speed_dating[which(speed_dating$iid == pid)[1], x] } for (i in 1:nrow(speed_dating)) { result[i,1] &lt;- if_else((tmp[i,1] &gt;=7 &amp; speed_dating[i,x]&gt;=7), &#39;Yes&#39;, &#39;No&#39;) } return(result) } # append the newly added columns to the original data frame names = colnames(speed_dating %&gt;% select(sports:yoga)) common_features &lt;- as.data.frame(do.call(cbind,lapply(names, f))) colnames(common_features)&lt;- paste0(&#39;same&#39;,colnames(speed_dating %&gt;% select(sports:yoga))) speed_dating &lt;- cbind(speed_dating, common_features) speed_dating &lt;- speed_dating[, !duplicated(colnames(speed_dating))] # drop unecessary columns and missing data drops = c(&#39;plocation&#39;, &#39;pfield&#39;) speed_dating &lt;- select(speed_dating, -drops) keeps = append(paste0(&#39;same&#39;,colnames(speed_dating %&gt;% select(sports:yoga))), c(&#39;samelocation&#39;, &#39;samefield&#39;)) speed_dating &lt;- speed_dating[complete.cases(speed_dating[,keeps]), ] #save(speed_dating_q1, file = &quot;data/speed_dating_q1.Rdata&quot;) load(file = &quot;data/speed_dating_q1.Rdata&quot;) speed_dating &lt;- speed_dating_q1 names = colnames(speed_dating %&gt;% select(sports:yoga)) # for mosaic plot # create a clean dataframe for each common feature sameracedata = speed_dating %&gt;% group_by(samerace, match) %&gt;% summarise(Freq = n()) %&gt;% ungroup() %&gt;% mutate(samerace = if_else(samerace == 1, &quot;Yes&quot;, &quot;No&quot;)) %&gt;% mutate(match = if_else(match == 1, &quot;Yes&quot;, &quot;No&quot;)) samelocationdata = speed_dating %&gt;% group_by(samelocation, match) %&gt;% summarize(Freq = n()) %&gt;% ungroup() %&gt;% mutate(match = if_else(match == 1, &quot;Yes&quot;, &quot;No&quot;)) samefielddata = speed_dating %&gt;% group_by(samefield, match) %&gt;% summarize(Freq = n()) %&gt;% ungroup() %&gt;% mutate(match = if_else(match == 1, &quot;Yes&quot;, &quot;No&quot;)) samesportsdata = speed_dating %&gt;% group_by(samesports, match) %&gt;% summarize(Freq = n()) %&gt;% ungroup() %&gt;% mutate(match = if_else(match == 1, &quot;Yes&quot;, &quot;No&quot;)) samereadingdata = speed_dating %&gt;% group_by(samereading, match) %&gt;% summarize(Freq = n()) %&gt;% ungroup() %&gt;% mutate(match = if_else(match == 1, &quot;Yes&quot;, &quot;No&quot;)) samemoviesdata = speed_dating %&gt;% group_by(samemovies, match) %&gt;% summarize(Freq = n()) %&gt;% ungroup() %&gt;% mutate(match = if_else(match == 1, &quot;Yes&quot;, &quot;No&quot;)) cat( paste( &#39;&lt;script&gt; var sameracedata = &#39;,toJSON(sameracedata),&#39;; var samelocationdata = &#39;,toJSON(samelocationdata),&#39;; var samefielddata = &#39;,toJSON(samefielddata),&#39;; var samesportsdata = &#39;,toJSON(samesportsdata),&#39;; var samereadingdata = &#39;,toJSON(samereadingdata),&#39;; var samemoviesdata = &#39;,toJSON(samemoviesdata),&#39;; &lt;/script&gt;&#39; , sep=&quot;&quot;) ) We then look at all the available features that could be of common interest in the dataset, and see if any of those features heavily impacts the chances of getting matched. calc_diff &lt;- function(y){ tmp &lt;- speed_dating %&gt;% group_by_(y, &#39;match&#39;) %&gt;% summarize(Freq = n()) %&gt;% ungroup() %&gt;% mutate(match = if_else(match == 1, &quot;Yes&quot;, &quot;No&quot;)) no_rate &lt;- tmp[2,3]/(tmp[2,3]+tmp[1,3]) yes_rate &lt;- tmp[4,3]/(tmp[3,3]+tmp[4,3]) hobby &lt;- substring(as.character(y), 5) result &lt;- data.frame(&quot;hobby&quot; = c(hobby,hobby), &quot;share_hobby&quot; = c(&quot;Yes&quot;, &quot;No&quot;), &quot;Freq&quot; = c(0,0)) result[1,3] &lt;-yes_rate*100 result[2,3] &lt;-no_rate*100 return(result) } cd_df &lt;- do.call(rbind,lapply(paste0(&#39;same&#39;,colnames(speed_dating %&gt;% select(sports:yoga))),calc_diff)) ggplot(cd_df,aes(x=Freq,y=fct_reorder2(hobby, share_hobby == &#39;Yes&#39;,Freq, .desc=FALSE), color = fct_rev(share_hobby)))+geom_point(size = 3)+ylab(&quot;Hobbies&quot;)+xlab(&quot;Percent (%)&quot;)+ggtitle(&quot;Chances of Matching&quot;)+labs(color=&quot;Participants Share this Hobby&quot;)+theme(axis.text.x = element_text(size = 14), axis.title.x = element_text(size = 16), axis.text.y = element_text(size = 14), axis.title.y = element_text(size = 16), plot.title = element_text(size = 20, face = &quot;bold&quot;), legend.title = element_text(size=16), legend.text = element_text(size=14)) "],
["interactive-component.html", "Chapter 6 Interactive component", " Chapter 6 Interactive component "],
["conclusion.html", "Chapter 7 Conclusion 7.1 Question: Will backrgound and common interests influence the match? Which feature is the most influential?", " Chapter 7 Conclusion 7.1 Question: Will backrgound and common interests influence the match? Which feature is the most influential? To answer this question, we have to look at background and common interests seperately. Background includes three features: race, from, and field. We can do so by comparing the chance of matching by conditioning on whether they are from the same race, same from (location), and same field. Data Cleaning: we would like to append 6 indicator columns that indicates whether this person and his/her partner share that feature in common (actually 5 because samerace is available in the original data). library(ggplot2) library(tidyverse) library(vcd) library(jsonlite) load(&#39;data/speed_dating.RData&#39;) # get feature values of the partner for (i in 1:nrow(speed_dating)) { # for each row, get partner&#39;s id pid = speed_dating[i, &#39;pid&#39;] # add temporary columns that holds partner&#39;s location, field, sports, reading, movies speed_dating[i, &#39;plocation&#39;] = speed_dating[which(speed_dating$iid == pid)[1], &#39;from&#39;] speed_dating[i, &#39;pfield&#39;] = speed_dating[which(speed_dating$iid == pid)[1], &#39;field&#39;] } # append indicator columns for location, field, and income speed_dating[&#39;samelocation&#39;] &lt;- if_else(speed_dating$from == speed_dating$plocation, &#39;Yes&#39;, &#39;No&#39;) speed_dating[&#39;samefield&#39;] &lt;- if_else(speed_dating$field == speed_dating$pfield, &#39;Yes&#39;, &#39;No&#39;) # get the feature values of all the hobbies of the partner f &lt;- function(x){ tmp &lt;- data.frame(&quot;holder&quot; = 1:dim(speed_dating)[1]) result &lt;- data.frame(&quot;holder&quot; = 1:dim(speed_dating)[1]) for (i in 1:nrow(speed_dating)){ pid = speed_dating[i, &#39;pid&#39;] tmp[i,1] &lt;- speed_dating[which(speed_dating$iid == pid)[1], x] } for (i in 1:nrow(speed_dating)) { result[i,1] &lt;- if_else((tmp[i,1] &gt;=7 &amp; speed_dating[i,x]&gt;=7), &#39;Yes&#39;, &#39;No&#39;) } return(result) } # append the newly added columns to the original data frame names = colnames(speed_dating %&gt;% select(sports:yoga)) common_features &lt;- as.data.frame(do.call(cbind,lapply(names, f))) colnames(common_features)&lt;- paste0(&#39;same&#39;,colnames(speed_dating %&gt;% select(sports:yoga))) speed_dating &lt;- cbind(speed_dating, common_features) speed_dating &lt;- speed_dating[, !duplicated(colnames(speed_dating))] # drop unecessary columns and missing data drops = c(&#39;plocation&#39;, &#39;pfield&#39;) speed_dating &lt;- select(speed_dating, -drops) keeps = append(paste0(&#39;same&#39;,colnames(speed_dating %&gt;% select(sports:yoga))), c(&#39;samelocation&#39;, &#39;samefield&#39;)) speed_dating &lt;- speed_dating[complete.cases(speed_dating[,keeps]), ] #save(speed_dating_q1, file = &quot;data/speed_dating_q1.Rdata&quot;) load(file = &quot;data/speed_dating_q1.Rdata&quot;) speed_dating &lt;- speed_dating_q1 names = colnames(speed_dating %&gt;% select(sports:yoga)) # for mosaic plot # create a clean dataframe for each common feature sameracedata = speed_dating %&gt;% group_by(samerace, match) %&gt;% summarise(Freq = n()) %&gt;% ungroup() %&gt;% mutate(samerace = if_else(samerace == 1, &quot;Yes&quot;, &quot;No&quot;)) %&gt;% mutate(match = if_else(match == 1, &quot;Yes&quot;, &quot;No&quot;)) samelocationdata = speed_dating %&gt;% group_by(samelocation, match) %&gt;% summarize(Freq = n()) %&gt;% ungroup() %&gt;% mutate(match = if_else(match == 1, &quot;Yes&quot;, &quot;No&quot;)) samefielddata = speed_dating %&gt;% group_by(samefield, match) %&gt;% summarize(Freq = n()) %&gt;% ungroup() %&gt;% mutate(match = if_else(match == 1, &quot;Yes&quot;, &quot;No&quot;)) samesportsdata = speed_dating %&gt;% group_by(samesports, match) %&gt;% summarize(Freq = n()) %&gt;% ungroup() %&gt;% mutate(match = if_else(match == 1, &quot;Yes&quot;, &quot;No&quot;)) samereadingdata = speed_dating %&gt;% group_by(samereading, match) %&gt;% summarize(Freq = n()) %&gt;% ungroup() %&gt;% mutate(match = if_else(match == 1, &quot;Yes&quot;, &quot;No&quot;)) samemoviesdata = speed_dating %&gt;% group_by(samemovies, match) %&gt;% summarize(Freq = n()) %&gt;% ungroup() %&gt;% mutate(match = if_else(match == 1, &quot;Yes&quot;, &quot;No&quot;)) cat( paste( &#39;&lt;script&gt; var sameracedata = &#39;,toJSON(sameracedata),&#39;; var samelocationdata = &#39;,toJSON(samelocationdata),&#39;; var samefielddata = &#39;,toJSON(samefielddata),&#39;; var samesportsdata = &#39;,toJSON(samesportsdata),&#39;; var samereadingdata = &#39;,toJSON(samereadingdata),&#39;; var samemoviesdata = &#39;,toJSON(samemoviesdata),&#39;; &lt;/script&gt;&#39; , sep=&quot;&quot;) ) We then look at all the available features that could be of common interest in the dataset, and see if any of those features heavily impacts the chances of getting matched. calc_diff &lt;- function(y){ tmp &lt;- speed_dating %&gt;% group_by_(y, &#39;match&#39;) %&gt;% summarize(Freq = n()) %&gt;% ungroup() %&gt;% mutate(match = if_else(match == 1, &quot;Yes&quot;, &quot;No&quot;)) no_rate &lt;- tmp[2,3]/(tmp[2,3]+tmp[1,3]) yes_rate &lt;- tmp[4,3]/(tmp[3,3]+tmp[4,3]) hobby &lt;- substring(as.character(y), 5) result &lt;- data.frame(&quot;hobby&quot; = c(hobby,hobby), &quot;share_hobby&quot; = c(&quot;Yes&quot;, &quot;No&quot;), &quot;Freq&quot; = c(0,0)) result[1,3] &lt;-yes_rate*100 result[2,3] &lt;-no_rate*100 return(result) } cd_df &lt;- do.call(rbind,lapply(paste0(&#39;same&#39;,colnames(speed_dating %&gt;% select(sports:yoga))),calc_diff)) ggplot(cd_df,aes(x=Freq,y=fct_reorder2(hobby, share_hobby == &#39;Yes&#39;,Freq, .desc=FALSE), color = fct_rev(share_hobby)))+geom_point(size = 3)+ylab(&quot;Hobbies&quot;)+xlab(&quot;Percent (%)&quot;)+ggtitle(&quot;Chances of Matching&quot;)+labs(color=&quot;Participants Share this Hobby&quot;)+theme(axis.text.x = element_text(size = 14), axis.title.x = element_text(size = 16), axis.text.y = element_text(size = 14), axis.title.y = element_text(size = 16), plot.title = element_text(size = 20, face = &quot;bold&quot;), legend.title = element_text(size=16), legend.text = element_text(size=14)) "]
>>>>>>> ef2a7eee1340762d1ab8e02daa07f097bb0fb3d0
]
